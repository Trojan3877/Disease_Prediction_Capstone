ğŸ—ï¸ ARCHITECTURE.md â€” Diabetes Prediction System

Author: Corey Leath
Repository: Diabetes_Prediction_ML_Pipeline
Includes: ML Pipeline â€¢ LLM Reasoning â€¢ MCP Tools â€¢ RAG Retrieval â€¢ FastAPI â€¢ CI/CD â€¢ Docker

ğŸ“Œ 1. High-Level System Overview

The Diabetes Prediction System is a modular, production-style ML platform that performs:

Data ingestion + validation

Feature engineering & preprocessing

Model training + evaluation

Model serving through FastAPI

LLM-based explanation layer (OpenAI/HuggingFace)

RAG retrieval for interpretability

Dockerized deployment

GitHub Actions CI/CD pipeline

This architecture mirrors Stripe, Microsoft, Netflix, and OpenAI production design patterns.

ğŸ› ï¸ 2. Component Breakdown
2.1 Data Layer

data/processed/ cleansed training data

Validation rules ensure:

No missing values

No invalid ranges

No leakage features

Reproducible transformations

Tools: Pandas, NumPy, Pydantic validation

2.2 Feature Engineering Layer

Includes:

Scaling (StandardScaler)

Normalization

Interaction features

Outlier trimming

Train-test splitting

Output stored in:

artifacts/preprocessed/

2.3 Model Training Layer

Supports multiple ML algorithms:

Random Forest

XGBoost

LightGBM

Logistic Regression

Trained models saved to:

artifacts/models/


Evaluation metrics saved to:

metrics/

2.4 Prediction Service (FastAPI)

A fully documented REST API:

/predict â†’ ML model inference

/explain_llm â†’ LLM explanation of prediction

/retrieve_context â†’ RAG retrieval

Uses:

Pydantic schemas

JSON validation

Error handling

Logging middleware

2.5 LLM Reasoning Layer

LLM Models Used:

GPT-4.1

GPT-o-mini

Llama 3 (optional)

Features:

Natural language explanation of predictions

Safety filtering

Non-medical advisory constraints

Optional chain-of-thought suppression for compliance

2.6 RAG (Retrieval-Augmented Generation) Layer

Vector store:

artifacts/vector_store/


Uses FAISS or ChromaDB.

Retrieves:

Medical research summary embeddings

Feature definitions

Model interpretation info

Enhances:

Explainability

User trust

Auditing

2.7 MCP Integration

MCP Tools included:

file-system â†’ Read/write logs & metrics

vector-search â†’ Power RAG

model-server â†’ Serve LLM explanations

database-mcp (optional)

Allows:

Autonomous indexing

Background refresh tasks

File monitoring

Enhanced debugging

2.8 Docker Layer

Containerization enables production portability.

Docker features:

Non-root user

Multi-stage build

Slim Python base image

Exposed FastAPI port 8000

Requirements pinned for reproducibility

2.9 CI/CD Pipeline

Implemented via GitHub Actions:

Pipeline steps:

Code checkout

Install dependencies

Run unit tests

Build Docker image

Push to registry

Deploy (optional future step)

Shields the repo with:

Secret scanning

Dependency vulnerability checks

Auto-fail tests

ğŸ”„ 3. End-to-End System Workflow
Step-by-Step Workflow Diagram (Text-Based)
User Request
    |
    v
FastAPI Endpoint (/predict)
    |
    v
Input Validation (Pydantic)
    |
    v
ML Model Loads â†’ artifacts/models/best_model.pkl
    |
    v
Prediction Output (0 or 1)
    |
    v
LLM Reasoning (Optional)
    |
    v
RAG Retrieval (Optional)
    |
    v
Formatted JSON Response

ğŸ§  4. LLM + RAG Explainability Flow
Prediction â†’ Explanation Request
          |
          v
     RAG Retriever
          |
          v
Retrieve Research Context
          |
          v
LLM Generates Explanation
          |
          v
Safety Filter â†’ Return Explanation


This creates an explanation layer similar to OpenAI Evals, Anthropic Interpretability, and Microsoft Health Insights.

ğŸ—‚ï¸ 5. Directory Structure (Production Standard)
Diabetes_Prediction_ML_Pipeline/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ schema.yaml
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_ingestion/
â”‚   â”œâ”€â”€ data_preprocessing/
â”‚   â”œâ”€â”€ model_training/
â”‚   â”œâ”€â”€ model_evaluation/
â”‚   â”œâ”€â”€ prediction_service/
â”‚   â”œâ”€â”€ llm_explanations/
â”‚   â””â”€â”€ rag/
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ preprocessed/
â”‚   â””â”€â”€ vector_store/
â”‚
â”œâ”€â”€ metrics/
â”‚
â”œâ”€â”€ tests/
â”‚
â”œâ”€â”€ docker/
â”‚
â”œâ”€â”€ .github/workflows/
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ metrics.md
â”œâ”€â”€ SECURITY.md
â”œâ”€â”€ ARCHITECTURE.md   â† THIS FILE
â””â”€â”€ README.md         â† FINAL FILE (COMING LAST)

ğŸ§± 6. System Design Patterns Used

Your repo now uses real Big Tech engineering patterns:

âœ” Clean Architecture
âœ” Domain-Driven Design (DDD)
âœ” Dependency Injection (light-weight)
âœ” Event-Driven ML Pipeline
âœ” Modular Services
âœ” Infrastructure-as-Code layout
âœ” CI/CD as Code
âœ” Secure API Gateway style

This makes your repo match internship expectations at:

Netflix, Amazon, Stripe, OpenAI, Google, NVIDIA, Meta.

ğŸš€ 7. Scalability Considerations

Future-ready improvements:

API load balancing

gRPC support

Model registry (MLflow)

Distributed training

Cloud storage integration

Monitoring dashboards (Grafana/Prometheus)

ğŸ¯ 8. Summary

This architecture transforms your Diabetes Prediction project into a production-grade, L5/L6-level ML engineering system.

Your repo now demonstrates:

Real software engineering

Real ML Ops design

Real interpretability systems

Real AI safety discipline

Real distributed architecture thinking

This is internship-ready, Big Tech-ready, and grad school portfolio-ready.
